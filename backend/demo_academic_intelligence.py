#!/usr/bin/env python3
"""
–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –ø–æ–∫–∞–∑–∞ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π 
—Å–∏—Å—Ç–µ–º—ã –∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫–æ–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç–∏ –∏ —Å–æ–∑–¥–∞–Ω–∏—è —Ü–∏—Ñ—Ä–æ–≤–æ–≥–æ –¥–≤–æ–π–Ω–∏–∫–∞
"""

import asyncio
import json
import sys
import os
from datetime import datetime

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

try:
    from modules.academic_intelligence import AcademicIntelligenceCollector, AcademicDataExtractor, AcademicSearchResult
    from modules.digital_twin import DigitalTwinCreator
    print("‚úÖ –ú–æ–¥—É–ª–∏ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã —É—Å–ø–µ—à–Ω–æ")
except ImportError as e:
    print(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {e}")
    sys.exit(1)

def create_demo_academic_data():
    """–°–æ–∑–¥–∞–Ω–∏–µ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö –∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö"""
    return {
        'email': 'john.smith@stanford.edu',
        'academic_profile': {
            'name': 'Dr. John Smith',
            'email': 'john.smith@stanford.edu',
            'degrees': [
                {
                    'degree': 'PhD in Computer Science',
                    'university': 'MIT',
                    'year': '2010',
                    'context': 'John Smith received his PhD in Computer Science from MIT in 2010'
                },
                {
                    'degree': 'MS in Artificial Intelligence',
                    'university': 'Stanford University',
                    'year': '2007',
                    'context': 'Master of Science in Artificial Intelligence from Stanford University in 2007'
                }
            ],
            'positions': [
                {
                    'position': 'Professor',
                    'university': 'Stanford University',
                    'department': 'Computer Science Department',
                    'context': 'Professor at Stanford University, Computer Science Department since 2015'
                },
                {
                    'position': 'Associate Professor',
                    'university': 'UC Berkeley',
                    'department': 'EECS',
                    'context': 'Associate Professor at UC Berkeley EECS from 2012-2015'
                }
            ],
            'institutions': ['Stanford University', 'MIT', 'UC Berkeley'],
            'research_areas': [
                'Artificial Intelligence', 
                'Machine Learning', 
                'Computer Vision', 
                'Deep Learning',
                'Neural Networks'
            ],
            'publications': [
                {
                    'title': 'Deep Learning for Computer Vision: A Comprehensive Survey',
                    'journal': 'Nature Machine Intelligence',
                    'year': '2023',
                    'doi': '10.1038/s42256-023-00123-x',
                    'context': 'Published comprehensive survey on deep learning applications in computer vision'
                },
                {
                    'title': 'Transformer Networks for Image Recognition',
                    'journal': 'NeurIPS',
                    'year': '2022',
                    'context': 'Groundbreaking work on applying transformer architectures to image recognition tasks'
                },
                {
                    'title': 'Federated Learning in Healthcare Applications',
                    'journal': 'Journal of Medical AI',
                    'year': '2023',
                    'context': 'Novel approach to privacy-preserving machine learning in medical settings'
                },
                {
                    'title': 'Adversarial Training for Robust Neural Networks',
                    'journal': 'ICML',
                    'year': '2021',
                    'context': 'Innovative methods for training neural networks resistant to adversarial attacks'
                }
            ],
            'academic_websites': [
                'https://scholar.google.com/citations?user=abc123',
                'https://www.researchgate.net/profile/John-Smith-123',
                'https://stanford.edu/~jsmith'
            ],
            'academic_ids': {
                'orcid': '0000-0002-1234-5678',
                'google_scholar': 'abc123def456'
            },
            'academic_rank': 'Professor'
        },
        'search_results': [
            {
                'title': 'Dr. John Smith - Stanford Faculty',
                'url': 'https://cs.stanford.edu/people/john-smith',
                'snippet': 'John Smith is a Professor of Computer Science at Stanford University. His research focuses on artificial intelligence, machine learning, and computer vision.',
                'source': 'google',
                'rank': 1,
                'academic_score': 0.95
            },
            {
                'title': 'John Smith - Google Scholar',
                'url': 'https://scholar.google.com/citations?user=abc123',
                'snippet': 'John Smith, Stanford University - Cited by 15,000+ - artificial intelligence, machine learning, computer vision',
                'source': 'google',
                'rank': 2,
                'academic_score': 0.92
            },
            {
                'title': 'Publications by John Smith - ResearchGate',
                'url': 'https://www.researchgate.net/profile/John-Smith-123',
                'snippet': 'John Smith has published 45+ papers in top-tier conferences and journals including Nature, NeurIPS, ICML',
                'source': 'google',
                'rank': 3,
                'academic_score': 0.88
            }
        ],
        'confidence_scores': {
            'overall': 0.92,
            'degrees': 0.95,
            'positions': 0.90,
            'publications': 0.88,
            'academic_status': 0.95
        },
        'analysis_summary': {
            'total_search_results': 15,
            'academic_results': 12,
            'high_confidence_results': 8,
            'platforms_found': 3,
            'degrees_found': 2,
            'positions_found': 2,
            'publications_found': 4,
            'institutions_found': 3,
            'research_areas_found': 5,
            'has_name': True,
            'has_academic_rank': True,
            'academic_ids_found': 2
        },
        'collection_timestamp': datetime.now().isoformat()
    }

async def demo_academic_intelligence():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫–æ–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç–∏"""
    print("\n" + "="*70)
    print("üî¨ –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø –ê–ö–ê–î–ï–ú–ò–ß–ï–°–ö–û–ô –ò–ù–¢–ï–õ–õ–ï–ö–¢–£–ê–õ–¨–ù–û–°–¢–ò")
    print("="*70)
    
    # –°–æ–∑–¥–∞–µ–º –¥–µ–º–æ-–¥–∞–Ω–Ω—ã–µ
    demo_data = create_demo_academic_data()
    
    print(f"\nüìß –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã–π email: {demo_data['email']}")
    print(f"üë§ –ò–¥–µ–Ω—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–º—è: {demo_data['academic_profile']['name']}")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–µ–ø–µ–Ω–∏
    print(f"\nüéì –ê–ö–ê–î–ï–ú–ò–ß–ï–°–ö–ò–ï –°–¢–ï–ü–ï–ù–ò ({len(demo_data['academic_profile']['degrees'])} –Ω–∞–π–¥–µ–Ω–æ):")
    for i, degree in enumerate(demo_data['academic_profile']['degrees'], 1):
        print(f"  {i}. {degree['degree']}")
        print(f"     üìç {degree['university']} ({degree['year']})")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –¥–æ–ª–∂–Ω–æ—Å—Ç–∏
    print(f"\nüíº –ê–ö–ê–î–ï–ú–ò–ß–ï–°–ö–ò–ï –î–û–õ–ñ–ù–û–°–¢–ò ({len(demo_data['academic_profile']['positions'])} –Ω–∞–π–¥–µ–Ω–æ):")
    for i, position in enumerate(demo_data['academic_profile']['positions'], 1):
        print(f"  {i}. {position['position']}")
        print(f"     üèõÔ∏è {position['university']} - {position['department']}")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ–±–ª–∞—Å—Ç–∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π
    print(f"\nüî¨ –û–ë–õ–ê–°–¢–ò –ò–°–°–õ–ï–î–û–í–ê–ù–ò–ô ({len(demo_data['academic_profile']['research_areas'])} –Ω–∞–π–¥–µ–Ω–æ):")
    for i, area in enumerate(demo_data['academic_profile']['research_areas'], 1):
        print(f"  {i}. {area}")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
    print(f"\nüìö –ü–£–ë–õ–ò–ö–ê–¶–ò–ò ({len(demo_data['academic_profile']['publications'])} –Ω–∞–π–¥–µ–Ω–æ):")
    for i, pub in enumerate(demo_data['academic_profile']['publications'], 1):
        print(f"  {i}. \"{pub['title']}\"")
        print(f"     üìñ {pub['journal']} ({pub['year']})")
        if pub.get('doi'):
            print(f"     üîó DOI: {pub['doi']}")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ—Ñ–∏–ª–∏
    print(f"\nüåê –ê–ö–ê–î–ï–ú–ò–ß–ï–°–ö–ò–ï –ü–†–û–§–ò–õ–ò ({len(demo_data['academic_profile']['academic_websites'])} –Ω–∞–π–¥–µ–Ω–æ):")
    platform_names = {
        'scholar.google.com': 'Google Scholar',
        'researchgate.net': 'ResearchGate',
        'stanford.edu': 'Stanford Personal Page'
    }
    
    for i, website in enumerate(demo_data['academic_profile']['academic_websites'], 1):
        platform = next((name for domain, name in platform_names.items() if domain in website), 'Unknown Platform')
        print(f"  {i}. {platform}")
        print(f"     üîó {website}")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
    print(f"\nüìä –ú–ï–¢–†–ò–ö–ò –£–í–ï–†–ï–ù–ù–û–°–¢–ò:")
    confidence = demo_data['confidence_scores']
    print(f"  üéØ –û–±—â–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence['overall']:.1%}")
    print(f"  üéì –°—Ç–µ–ø–µ–Ω–∏: {confidence['degrees']:.1%}")
    print(f"  üíº –î–æ–ª–∂–Ω–æ—Å—Ç–∏: {confidence['positions']:.1%}")
    print(f"  üìö –ü—É–±–ª–∏–∫–∞—Ü–∏–∏: {confidence['publications']:.1%}")
    print(f"  üèõÔ∏è –ê–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏–π —Å—Ç–∞—Ç—É—Å: {confidence['academic_status']:.1%}")
    
    return demo_data

async def demo_digital_twin_creation(academic_data):
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Å–æ–∑–¥–∞–Ω–∏—è —Ü–∏—Ñ—Ä–æ–≤–æ–≥–æ –¥–≤–æ–π–Ω–∏–∫–∞"""
    print("\n" + "="*70)
    print("ü§ñ –°–û–ó–î–ê–ù–ò–ï –¶–ò–§–†–û–í–û–ì–û –î–í–û–ô–ù–ò–ö–ê")
    print("="*70)
    
    print("\n‚è≥ –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ–±—Ä–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏ —Å–æ–∑–¥–∞–µ–º —Ü–∏—Ñ—Ä–æ–≤–æ–≥–æ –¥–≤–æ–π–Ω–∏–∫–∞...")
    
    # –°–æ–∑–¥–∞–µ–º —Ü–∏—Ñ—Ä–æ–≤–æ–≥–æ –¥–≤–æ–π–Ω–∏–∫–∞
    twin_creator = DigitalTwinCreator()
    digital_twin = twin_creator.create_digital_twin(
        academic_data['email'],
        academic_data,
        academic_data['search_results']
    )
    
    print(f"‚úÖ –¶–∏—Ñ—Ä–æ–≤–æ–π –¥–≤–æ–π–Ω–∏–∫ —Å–æ–∑–¥–∞–Ω –¥–ª—è {digital_twin.email}")
    
    # –û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
    print(f"\nüë§ –û–°–ù–û–í–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø:")
    print(f"  üìß Email: {digital_twin.email}")
    print(f"  üë§ –ò–º—è: {digital_twin.name}")
    print(f"  üèõÔ∏è –û—Å–Ω–æ–≤–Ω–∞—è –∞—Ñ—Ñ–∏–ª–∏–∞—Ü–∏—è: {digital_twin.primary_affiliation}")
    
    # –ü—Ä–æ—Ñ–∏–ª—å –ª–∏—á–Ω–æ—Å—Ç–∏
    print(f"\nüß† –ü–†–û–§–ò–õ–¨ –õ–ò–ß–ù–û–°–¢–ò:")
    personality = digital_twin.personality_profile
    print(f"  üé≠ –°—Ç–∞–¥–∏—è –∫–∞—Ä—å–µ—Ä—ã: {personality.career_stage}")
    print(f"  üéØ –£—Ä–æ–≤–µ–Ω—å —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—ã: {personality.expertise_level}")
    print(f"  üí¨ –°—Ç–∏–ª—å –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏: {personality.communication_style}")
    print(f"  üî¨ –§–æ–∫—É—Å –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π: {personality.research_focus}")
    print(f"  ü§ù –°–∫–ª–æ–Ω–Ω–æ—Å—Ç—å –∫ —Å–æ—Ç—Ä—É–¥–Ω–∏—á–µ—Å—Ç–≤—É: {personality.collaboration_tendency}")
    print(f"  üíª –¶–∏—Ñ—Ä–æ–≤–æ–µ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤–∏–µ: {personality.digital_presence}")
    
    # –°–µ—Ç–µ–≤–æ–π –∞–Ω–∞–ª–∏–∑
    print(f"\nüï∏Ô∏è –°–ï–¢–ï–í–û–ô –ê–ù–ê–õ–ò–ó:")
    network = digital_twin.network_analysis
    print(f"  üë• –†–∞–∑–º–µ—Ä —Å–µ—Ç–∏: {network.network_size}")
    print(f"  üìà –ü–æ–∫–∞–∑–∞—Ç–µ–ª—å –≤–ª–∏—è–Ω–∏—è: {network.influence_score:.2f}")
    print(f"  üéØ –ü–æ–∫–∞–∑–∞—Ç–µ–ª—å —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ—Å—Ç–∏: {network.centrality_score:.2f}")
    print(f"  üèõÔ∏è –ò–Ω—Å—Ç–∏—Ç—É—Ü–∏–∏ ({len(network.institutions)}): {', '.join(network.institutions[:3])}")
    if len(network.collaborators) > 0:
        print(f"  ü§ù –ö–ª—é—á–µ–≤—ã–µ –∫–æ–ª–ª–∞–±–æ—Ä–∞—Ç–æ—Ä—ã: {', '.join(network.collaborators[:3])}")
    
    # –ö–∞—Ä—å–µ—Ä–Ω–∞—è —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏—è
    print(f"\nüìà –ö–ê–†–¨–ï–†–ù–ê–Ø –¢–†–ê–ï–ö–¢–û–†–ò–Ø:")
    career = digital_twin.career_trajectory
    print(f"  üìä –ü—Ä–æ–≥—Ä–µ—Å—Å–∏—è –∫–∞—Ä—å–µ—Ä—ã: {career.career_progression}")
    if career.experience_years:
        print(f"  ‚è±Ô∏è –õ–µ—Ç –æ–ø—ã—Ç–∞: {career.experience_years}")
    print(f"  üéØ –ö–ª—é—á–µ–≤—ã–µ –≤–µ—Ö–∏: {len(career.career_milestones)}")
    for milestone in career.career_milestones[:3]:
        print(f"    ‚Ä¢ {milestone['description']} ({milestone['year']})")
    
    # –ú–µ—Ç—Ä–∏–∫–∏ –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏—è
    print(f"\nüí• –ú–ï–¢–†–ò–ö–ò –í–û–ó–î–ï–ô–°–¢–í–ò–Ø:")
    impact = digital_twin.impact_metrics
    print(f"  üåü –û–±—â–∏–π –±–∞–ª–ª –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏—è: {impact.overall_impact_score:.2f}")
    print(f"  üìö –í–ª–∏—è–Ω–∏–µ —á–µ—Ä–µ–∑ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏:")
    citation = impact.citation_impact
    print(f"    ‚Ä¢ –ü—É–±–ª–∏–∫–∞—Ü–∏–π: {citation.get('publication_count', 0)}")
    print(f"    ‚Ä¢ –ü—Ä–∏–º–µ—Ä–Ω—ã–µ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {citation.get('estimated_citations', 0)}")
    print(f"    ‚Ä¢ –û—Ü–µ–Ω–∫–∞ h-index: {citation.get('h_index_estimate', 0)}")
    
    research_impact = impact.research_impact
    print(f"  üî¨ –ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–µ –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏–µ:")
    print(f"    ‚Ä¢ –®–∏—Ä–æ—Ç–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π: {research_impact.get('research_breadth', 0)}")
    print(f"    ‚Ä¢ –í–∏–¥–∏–º–æ—Å—Ç—å –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π: {research_impact.get('research_visibility', 0)}")
    print(f"    ‚Ä¢ –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –∏–Ω–Ω–æ–≤–∞—Ü–∏–æ–Ω–Ω–æ—Å—Ç–∏: {research_impact.get('innovation_indicators', 0)}")
    
    # –ü–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –∫–∞—á–µ—Å—Ç–≤–∞
    print(f"\nüìä –ü–û–ö–ê–ó–ê–¢–ï–õ–ò –ö–ê–ß–ï–°–¢–í–ê:")
    print(f"  üéØ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {digital_twin.confidence_score:.1%}")
    print(f"  üìà –ü–æ–ª–Ω–æ—Ç–∞ –¥–∞–Ω–Ω—ã—Ö: {digital_twin.completeness_score:.1%}")
    print(f"  üì° –ò—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–∞–Ω–Ω—ã—Ö: {len(digital_twin.data_sources)}")
    
    return digital_twin

def demo_visualization_data(digital_twin):
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏"""
    print("\n" + "="*70)
    print("üìä –î–ê–ù–ù–´–ï –î–õ–Ø –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–ò")
    print("="*70)
    
    viz_data = digital_twin.visualization_data
    
    print(f"\nüìã –î–æ—Å—Ç—É–ø–Ω—ã–µ —Ä–∞–∑–¥–µ–ª—ã –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ ({len(viz_data)}):")
    for section in viz_data.keys():
        print(f"  üìä {section}")
    
    # –î–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ–º —Ä–∞–¥–∞—Ä–Ω—É—é –¥–∏–∞–≥—Ä–∞–º–º—É –Ω–∞–≤—ã–∫–æ–≤
    if 'skill_radar' in viz_data:
        print(f"\nüéØ –†–ê–î–ê–†–ù–ê–Ø –î–ò–ê–ì–†–ê–ú–ú–ê –ù–ê–í–´–ö–û–í:")
        radar = viz_data['skill_radar']
        for category, value in zip(radar['categories'], radar['values']):
            bar_length = int(value * 20)  # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
            bar = "‚ñà" * bar_length + "‚ñë" * (20 - bar_length)
            print(f"  {category:20} |{bar}| {value:.1%}")
    
    # –î–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ–º —Å–µ—Ç–µ–≤–æ–π –≥—Ä–∞—Ñ
    if 'network_graph' in viz_data:
        print(f"\nüï∏Ô∏è –°–ï–¢–ï–í–û–ô –ì–†–ê–§:")
        network_graph = viz_data['network_graph']
        print(f"  üë§ –£–∑–ª–æ–≤ –≤ —Å–µ—Ç–∏: {len(network_graph['nodes'])}")
        print(f"  üîó –°–≤—è–∑–µ–π: {len(network_graph['edges'])}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–∏–ø—ã —É–∑–ª–æ–≤
        node_types = {}
        for node in network_graph['nodes']:
            node_type = node['type']
            node_types[node_type] = node_types.get(node_type, 0) + 1
        
        for node_type, count in node_types.items():
            print(f"    {node_type}: {count}")
    
    # –î–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ–º –æ–±–ª–∞–∫–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –æ–±–ª–∞—Å—Ç–µ–π
    if 'research_areas_cloud' in viz_data:
        print(f"\n‚òÅÔ∏è –û–ë–õ–ê–ö–û –ò–°–°–õ–ï–î–û–í–ê–¢–ï–õ–¨–°–ö–ò–• –û–ë–õ–ê–°–¢–ï–ô:")
        cloud = viz_data['research_areas_cloud']
        for word_data in cloud['words']:
            size_indicator = "‚óè" * min(5, word_data['size'] // 10)
            print(f"  {size_indicator} {word_data['text']}")
    
    # –î–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ–º –∫–∞—Ä—å–µ—Ä–Ω—É—é –≤—Ä–µ–º–µ–Ω–Ω—É—é –ª–∏–Ω–∏—é
    if 'career_timeline' in viz_data:
        print(f"\nüìÖ –ö–ê–†–¨–ï–†–ù–ê–Ø –í–†–ï–ú–ï–ù–ù–ê–Ø –õ–ò–ù–ò–Ø:")
        timeline = viz_data['career_timeline']
        print(f"  üìà –ü—Ä–æ–≥—Ä–µ—Å—Å–∏—è –∫–∞—Ä—å–µ—Ä—ã: {timeline['career_progression']}")
        if timeline.get('experience_years'):
            print(f"  ‚è±Ô∏è –õ–µ—Ç –æ–ø—ã—Ç–∞: {timeline['experience_years']}")
        
        events = timeline['events']
        print(f"  üéØ –°–æ–±—ã—Ç–∏—è ({len(events)}):")
        for event in events[:5]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5
            importance_stars = "‚≠ê" * min(5, event['importance'])
            print(f"    {event['year']} - {event['description']} {importance_stars}")

def demo_json_export(digital_twin):
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —ç–∫—Å–ø–æ—Ä—Ç–∞ –≤ JSON"""
    print("\n" + "="*70)
    print("üíæ –≠–ö–°–ü–û–†–¢ –î–ê–ù–ù–´–•")
    print("="*70)
    
    twin_creator = DigitalTwinCreator()
    
    # –°–æ–∑–¥–∞–µ–º —Å–≤–æ–¥–∫—É
    summary = twin_creator.generate_twin_summary(digital_twin)
    
    print(f"\nüìã –ö–†–ê–¢–ö–ê–Ø –°–í–û–î–ö–ê:")
    print(f"  üë§ –õ–∏—á–Ω–æ—Å—Ç—å:")
    identity = summary['identity']
    for key, value in identity.items():
        print(f"    {key}: {value}")
    
    print(f"  üéì –ê–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏–π —Å—Ç–∞—Ç—É—Å:")
    academic_status = summary['academic_status']
    for key, value in academic_status.items():
        print(f"    {key}: {value}")
    
    print(f"  üí• –°–≤–æ–¥–∫–∞ –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏—è:")
    impact_summary = summary['impact_summary']
    for key, value in impact_summary.items():
        print(f"    {key}: {value}")
    
    print(f"  üìä –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞:")
    quality_metrics = summary['quality_metrics']
    for key, value in quality_metrics.items():
        if isinstance(value, float):
            print(f"    {key}: {value:.1%}")
        else:
            print(f"    {key}: {value}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º JSON
    json_filename = f"digital_twin_demo_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    json_data = twin_creator.export_twin_to_json(digital_twin)
    
    with open(json_filename, 'w', encoding='utf-8') as f:
        f.write(json_data)
    
    print(f"\nüíæ –î–∞–Ω–Ω—ã–µ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –≤ —Ñ–∞–π–ª: {json_filename}")
    print(f"üìä –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {len(json_data)} —Å–∏–º–≤–æ–ª–æ–≤")

async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üöÄ –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø EMAIL INTELLIGENCE COLLECTOR")
    print("üéØ –ê–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∞—è –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å –∏ —Å–æ–∑–¥–∞–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–≤–æ–≥–æ –¥–≤–æ–π–Ω–∏–∫–∞")
    print("="*70)
    
    try:
        # 1. –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫–æ–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç–∏
        academic_data = await demo_academic_intelligence()
        
        input("\n‚èØÔ∏è  –ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è...")
        
        # 2. –°–æ–∑–¥–∞–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–≤–æ–≥–æ –¥–≤–æ–π–Ω–∏–∫–∞
        digital_twin = await demo_digital_twin_creation(academic_data)
        
        input("\n‚èØÔ∏è  –ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏...")
        
        # 3. –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
        demo_visualization_data(digital_twin)
        
        input("\n‚èØÔ∏è  –ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ –¥–∞–Ω–Ω—ã—Ö...")
        
        # 4. –≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö
        demo_json_export(digital_twin)
        
        print("\n" + "="*70)
        print("üéâ –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê –£–°–ü–ï–®–ù–û!")
        print("="*70)
        print("\nüìã –ß—Ç–æ –±—ã–ª–æ –ø—Ä–æ–¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–æ:")
        print("  ‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö (—Å—Ç–µ–ø–µ–Ω–∏, –¥–æ–ª–∂–Ω–æ—Å—Ç–∏, –ø—É–±–ª–∏–∫–∞—Ü–∏–∏)")
        print("  ‚úÖ –ê–Ω–∞–ª–∏–∑ –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –æ–±–ª–∞—Å—Ç–µ–π –∏ –∏–Ω—Å—Ç–∏—Ç—É—Ü–∏–π")
        print("  ‚úÖ –°–æ–∑–¥–∞–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–≤–æ–≥–æ –¥–≤–æ–π–Ω–∏–∫–∞ —Å –∞–Ω–∞–ª–∏–∑–æ–º –ª–∏—á–Ω–æ—Å—Ç–∏")
        print("  ‚úÖ –°–µ—Ç–µ–≤–æ–π –∞–Ω–∞–ª–∏–∑ –∏ –∫–∞—Ä—å–µ—Ä–Ω–∞—è —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏—è")
        print("  ‚úÖ –ú–µ—Ç—Ä–∏–∫–∏ –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏—è –∏ –≤–ª–∏—è–Ω–∏—è")
        print("  ‚úÖ –î–∞–Ω–Ω—ã–µ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ (–≥—Ä–∞—Ñ–∏–∫–∏, –¥–∏–∞–≥—Ä–∞–º–º—ã)")
        print("  ‚úÖ –≠–∫—Å–ø–æ—Ä—Ç –≤ JSON —Ñ–æ—Ä–º–∞—Ç")
        
        print("\nüî• –ö–ª—é—á–µ–≤—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ —Å–∏—Å—Ç–µ–º—ã:")
        print("  ‚Ä¢ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏")
        print("  ‚Ä¢ –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ª–∏—á–Ω–æ—Å—Ç–∏ –∏ –ø–æ–≤–µ–¥–µ–Ω–∏—è")
        print("  ‚Ä¢ –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∫–∞—Ä—å–µ—Ä–Ω–æ–π —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏")
        print("  ‚Ä¢ –°–µ—Ç–µ–≤–æ–π –∞–Ω–∞–ª–∏–∑ —Å–≤—è–∑–µ–π –∏ –∫–æ–ª–ª–∞–±–æ—Ä–∞—Ü–∏–π")
        print("  ‚Ä¢ –ú–µ—Ç—Ä–∏–∫–∏ –≤–ª–∏—è–Ω–∏—è –∏ –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏—è")
        print("  ‚Ä¢ –ì–æ—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏")
        print("  ‚Ä¢ API –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–º")
        
        print("\nüéØ –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ:")
        print("  ‚Ä¢ –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ—Ñ–∏–ª–µ–π")
        print("  ‚Ä¢ –ê–Ω–∞–ª–∏–∑ —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—ã –∏ –≤–ª–∏—è–Ω–∏—è")
        print("  ‚Ä¢ –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∫–∞—Ä—Ç –∑–Ω–∞–Ω–∏–π")
        print("  ‚Ä¢ –ü–æ–∏—Å–∫ –∫–æ–ª–ª–∞–±–æ—Ä–∞—Ç–æ—Ä–æ–≤ –∏ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤")
        print("  ‚Ä¢ –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫–æ–π –∫–∞—Ä—å–µ—Ä—ã")
        
        return True
        
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –≤ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)
