#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–æ–≤—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ä–∞–±–æ—Ç—ã –º–æ–¥—É–ª–µ–π –∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫–æ–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç–∏
"""

import asyncio
import json
import sys
import os
import logging

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

try:
    from modules.academic_intelligence import AcademicIntelligenceCollector, AcademicDataExtractor
    from modules.digital_twin import DigitalTwinCreator
    print("‚úÖ –ú–æ–¥—É–ª–∏ —É—Å–ø–µ—à–Ω–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã")
except ImportError as e:
    print(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ –º–æ–¥—É–ª–µ–π: {e}")
    sys.exit(1)

def test_academic_data_extractor():
    """–¢–µ—Å—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
    print("\nüî¨ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö...")
    
    extractor = AcademicDataExtractor()
    
    # –¢–µ—Å—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç —Å –∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
    test_text = """
    Dr. John Smith received his PhD in Computer Science from MIT in 2010. 
    He is currently a Professor at Stanford University, Department of Computer Science. 
    His research focuses on artificial intelligence and machine learning.
    He has published papers in top conferences like NeurIPS and ICML.
    John has collaborated with researchers from Google and Microsoft.
    """
    
    # –¢–µ—Å—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å—Ç–µ–ø–µ–Ω–µ–π
    degrees = extractor.extract_degrees(test_text)
    print(f"üìú –ù–∞–π–¥–µ–Ω–Ω—ã–µ —Å—Ç–µ–ø–µ–Ω–∏: {len(degrees)}")
    for degree in degrees:
        print(f"  - {degree['degree']} ({degree.get('year', '–Ω–µ–∏–∑–≤–µ—Å—Ç–µ–Ω')})")
    
    # –¢–µ—Å—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–æ–ª–∂–Ω–æ—Å—Ç–µ–π
    positions = extractor.extract_positions(test_text)
    print(f"üíº –ù–∞–π–¥–µ–Ω–Ω—ã–µ –¥–æ–ª–∂–Ω–æ—Å—Ç–∏: {len(positions)}")
    for position in positions:
        print(f"  - {position['position']} –≤ {position.get('university', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}")
    
    # –¢–µ—Å—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –æ–±–ª–∞—Å—Ç–µ–π –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π
    research_areas = extractor.extract_research_areas(test_text)
    print(f"üî¨ –û–±–ª–∞—Å—Ç–∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π: {research_areas}")
    
    return len(degrees) > 0 and len(positions) > 0

async def test_academic_search_simulation():
    """–°–∏–º—É–ª—è—Ü–∏—è –∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞ (–±–µ–∑ —Ä–µ–∞–ª—å–Ω—ã—Ö HTTP –∑–∞–ø—Ä–æ—Å–æ–≤)"""
    print("\nüîç –°–∏–º—É–ª—è—Ü–∏—è –∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞...")
    
    try:
        collector = AcademicIntelligenceCollector()
        
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º AcademicSearchResult –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ —Å–æ–∑–¥–∞–Ω–∏—è –æ–±—ä–µ–∫—Ç–æ–≤
        from modules.academic_intelligence import AcademicSearchResult
        
        # –°–æ–∑–¥–∞–µ–º –º–æ–∫-–¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        mock_search_results = [
            AcademicSearchResult(
                title='Dr. John Smith - Computer Science Professor',
                url='https://stanford.edu/faculty/john-smith',
                snippet='John Smith is a Professor of Computer Science at Stanford University. He received his PhD from MIT in 2010.',
                source='google',
                rank=1,
                academic_score=0.9
            ),
            AcademicSearchResult(
                title='Publications by John Smith - Google Scholar',
                url='https://scholar.google.com/citations?user=abc123',
                snippet='John Smith has published 25 papers in machine learning and artificial intelligence.',
                source='google',
                rank=2,
                academic_score=0.8
            )
        ]
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∞–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        profile_data = await collector._analyze_search_results(mock_search_results, "john.smith@stanford.edu")
        
        print(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞:")
        print(f"  - –°—Ç–µ–ø–µ–Ω–∏: {len(profile_data['degrees'])}")
        print(f"  - –î–æ–ª–∂–Ω–æ—Å—Ç–∏: {len(profile_data['positions'])}")
        print(f"  - –ò–Ω—Å—Ç–∏—Ç—É—Ü–∏–∏: {profile_data['institutions']}")
        print(f"  - –û–±–ª–∞—Å—Ç–∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π: {profile_data['research_areas']}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤ —Å–∏–º—É–ª—è—Ü–∏–∏ –ø–æ–∏—Å–∫–∞: {e}")
        return False

def test_digital_twin_creation():
    """–¢–µ—Å—Ç —Å–æ–∑–¥–∞–Ω–∏—è —Ü–∏—Ñ—Ä–æ–≤–æ–≥–æ –¥–≤–æ–π–Ω–∏–∫–∞"""
    print("\nü§ñ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–∑–¥–∞–Ω–∏—è —Ü–∏—Ñ—Ä–æ–≤–æ–≥–æ –¥–≤–æ–π–Ω–∏–∫–∞...")
    
    try:
        twin_creator = DigitalTwinCreator()
        
        # –ú–æ–∫-–¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–æ—Ñ–∏–ª—è
        mock_academic_data = {
            'academic_profile': {
                'email': 'john.smith@stanford.edu',
                'name': 'John Smith',
                'degrees': [
                    {
                        'degree': 'PhD',
                        'university': 'MIT',
                        'year': '2010',
                        'context': 'John Smith received his PhD in Computer Science from MIT in 2010'
                    }
                ],
                'positions': [
                    {
                        'position': 'Professor',
                        'university': 'Stanford University',
                        'department': 'Computer Science',
                        'context': 'Professor at Stanford University, Department of Computer Science'
                    }
                ],
                'institutions': ['Stanford University', 'MIT'],
                'research_areas': ['Artificial Intelligence', 'Machine Learning'],
                'publications': [
                    {
                        'title': 'Deep Learning for Computer Vision',
                        'journal': 'NeurIPS',
                        'year': '2020'
                    }
                ],
                'academic_websites': ['https://scholar.google.com/citations?user=abc123']
            },
            'confidence_scores': {
                'overall': 0.85,
                'degrees': 0.9,
                'positions': 0.8,
                'publications': 0.7
            }
        }
        
        mock_search_results = [
            {
                'title': 'Dr. John Smith - Stanford Faculty',
                'snippet': 'Professor of Computer Science specializing in AI research',
                'url': 'https://stanford.edu/faculty/john-smith',
                'academic_score': 0.9
            }
        ]
        
        # –°–æ–∑–¥–∞–µ–º —Ü–∏—Ñ—Ä–æ–≤–æ–≥–æ –¥–≤–æ–π–Ω–∏–∫–∞
        digital_twin = twin_creator.create_digital_twin(
            'john.smith@stanford.edu',
            mock_academic_data,
            mock_search_results
        )
        
        print(f"üé≠ –¶–∏—Ñ—Ä–æ–≤–æ–π –¥–≤–æ–π–Ω–∏–∫ —Å–æ–∑–¥–∞–Ω:")
        print(f"  - –ò–º—è: {digital_twin.name}")
        print(f"  - Email: {digital_twin.email}")
        print(f"  - –û—Å–Ω–æ–≤–Ω–∞—è –∞—Ñ—Ñ–∏–ª–∏–∞—Ü–∏—è: {digital_twin.primary_affiliation}")
        print(f"  - –°—Ç–∞–¥–∏—è –∫–∞—Ä—å–µ—Ä—ã: {digital_twin.personality_profile.career_stage}")
        print(f"  - –£—Ä–æ–≤–µ–Ω—å —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—ã: {digital_twin.personality_profile.expertise_level}")
        print(f"  - –û–±—â–∏–π –±–∞–ª–ª –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏—è: {digital_twin.impact_metrics.overall_impact_score:.2f}")
        print(f"  - –ë–∞–ª–ª —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏: {digital_twin.confidence_score:.2f}")
        print(f"  - –ë–∞–ª–ª –ø–æ–ª–Ω–æ—Ç—ã: {digital_twin.completeness_score:.2f}")
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é
        viz_data = digital_twin.visualization_data
        print(f"üìä –î–∞–Ω–Ω—ã–µ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏: {len(viz_data)} —Ä–∞–∑–¥–µ–ª–æ–≤")
        for section in viz_data.keys():
            print(f"  - {section}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ü–∏—Ñ—Ä–æ–≤–æ–≥–æ –¥–≤–æ–π–Ω–∏–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_api_imports():
    """–¢–µ—Å—Ç –∏–º–ø–æ—Ä—Ç–∞ API –º–æ–¥—É–ª–µ–π"""
    print("\nüåê –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–º–ø–æ—Ä—Ç–∞ API...")
    
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–º–ø–æ—Ä—Ç –æ—Å–Ω–æ–≤–Ω–æ–≥–æ API
        from app.main import app
        print("‚úÖ FastAPI –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω–æ–≤—ã—Ö —ç–Ω–¥–ø–æ–∏–Ω—Ç–æ–≤
        routes = [route.path for route in app.routes]
        expected_routes = [
            '/api/academic-search',
            '/api/digital-twin',
            '/api/academic-profile/{email}',
            '/api/digital-twin/{email}',
            '/api/visualization/{email}'
        ]
        
        missing_routes = []
        for route in expected_routes:
            if route not in routes:
                missing_routes.append(route)
        
        if missing_routes:
            print(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –º–∞—Ä—à—Ä—É—Ç—ã: {missing_routes}")
            return False
        else:
            print("‚úÖ –í—Å–µ –Ω–æ–≤—ã–µ API —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã –Ω–∞–π–¥–µ–Ω—ã")
            return True
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ API: {e}")
        return False

async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    print("üöÄ –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è Email Intelligence Collector (Academic Intelligence)")
    print("=" * 70)
    
    tests = [
        ("–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö", test_academic_data_extractor),
        ("–°–∏–º—É–ª—è—Ü–∏—è –∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞", test_academic_search_simulation),
        ("–°–æ–∑–¥–∞–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–≤–æ–≥–æ –¥–≤–æ–π–Ω–∏–∫–∞", test_digital_twin_creation),
        ("–ò–º–ø–æ—Ä—Ç API –º–æ–¥—É–ª–µ–π", test_api_imports)
    ]
    
    results = []
    
    for test_name, test_func in tests:
        print(f"\n{'='*50}")
        print(f"üß™ {test_name}")
        print(f"{'='*50}")
        
        try:
            if asyncio.iscoroutinefunction(test_func):
                result = await test_func()
            else:
                result = test_func()
            
            if result:
                print(f"‚úÖ {test_name}: –ü–†–û–ô–î–ï–ù")
            else:
                print(f"‚ùå {test_name}: –ù–ï –ü–†–û–ô–î–ï–ù")
            
            results.append((test_name, result))
            
        except Exception as e:
            print(f"‚ùå {test_name}: –û–®–ò–ë–ö–ê - {e}")
            results.append((test_name, False))
    
    # –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
    print(f"\n{'='*70}")
    print("üìã –ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢")
    print(f"{'='*70}")
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    for test_name, result in results:
        status = "‚úÖ –ü–†–û–ô–î–ï–ù" if result else "‚ùå –ù–ï –ü–†–û–ô–î–ï–ù"
        print(f"{test_name}: {status}")
    
    print(f"\n–ò—Ç–æ–≥–æ: {passed}/{total} —Ç–µ—Å—Ç–æ–≤ –ø—Ä–æ–π–¥–µ–Ω–æ")
    
    if passed == total:
        print("üéâ –í—Å–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ–π–¥–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ!")
        return True
    else:
        print("‚ö†Ô∏è –ù–µ–∫–æ—Ç–æ—Ä—ã–µ —Ç–µ—Å—Ç—ã –Ω–µ –ø—Ä–æ–π–¥–µ–Ω—ã")
        return False

if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)
